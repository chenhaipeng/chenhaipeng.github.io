- [Elasticsearch 底层数据结构](https://www.cnblogs.com/tech-lee/p/15225276.html)

# Elasticsearch 底层数据结构

Term index(trie 数) -> Term dictionary(term 文本) -> posting（倒排索引）

## 倒排索引
Elasticsearch分别为每个field都建立了一个倒排索引，一个字段有一个自己的倒排索引。Kate, John, 24, Female这些叫term，而[1,2]就是Posting List。Posting list就是一个int的数组，存储了所有符合某个term的文档id。

## Term Dictionary
假设我们有很多个 term，比如：Carla,Sara,Elin,Ada,Patty,Kate,Selena，这样我们可以用二分查找的方式，比全遍历更快地找出目标的 term。这个就是 term dictionary。


## 内存索引大小问题Term index
term index 是一棵 trie 树，再加上一些压缩技术（搜索 Lucene Finite State Transducers） term index 的尺寸可以只有所有 term 的尺寸的几十分之一，使得用内存缓存整个 term index 变成可能。
Mysql 只有tem dictionary 这一层，是以b-tree 排序的方式存储在磁盘上，检索一个term 需要若干次random access 磁盘操作，而lucene 在term dictionary 的基础上添加term index 来加速索引，
term index 以树的形式缓存在内存中，从term index 查到对应的term dictionary block 再去磁盘找term


## QA
## Q: ES 的底层存储结构是什么样的
A: 我们知道ES 提供的最强大的能力是检索，为了提供搜索性能，Elasticsearch 使用一种称为倒排索引的结构来快速检索，对于字段构成的文档，它对字段建立自己倒排索引，分为三部分
Term Index -> Term dictionary -> Post list;   Term dictionary 就是我词典， Post list 就是对于词的倒排， Term Index 是一颗一词典构成的trie 数，为什么要这样设计呢，
是因为ES 想要把整个索引存储成本太高了，如果想 mysql b+ 数来存储，需要的内存太大， term index 是一个前缀数数，能快速定位term dictionary 的某个offset , 再通过FST（Finite State Transducers）
压缩term index 

## Q:什么是Elasticsearch FST(Finite State Transducers)有限状态置换器
FSM(Finite State Machines)有限状态机: 表示有限个状态（State）集合以及这些状态之间转移和动作的数学模型。其中一个状态被标记为开始状态，0个或更多的状态被标记为final状态。一个FSM同一时间只处于1个状态。
FST有两个优点：
1) 空间暂用少，通过对词典单词的前缀和后缀重复利用，压缩了存储空间
2) 查询速度快，以O(len(n)) 的查询复杂度
对于经典FST算法来说，要求Key必须按字典序从小到大加入到FST中，原因主要是因为在处理大数据的情况下，我们不太可能把整个FST数据结构都同时放在内存中，而是要边建图边将建好的图存储在外部文件中，以便节省内存。所以我们第一步要对所有的Key排序，对于我给这个例子来说，已经保证了字典序的顺序。   

FST 的key 要求从少到大排序，按key:value 的值插入到FST中， cat->5 ,deep->10,do->15;

## Post List 压缩（Frame Of Reference）
posting list 进行排序。这个决定的一个很好的副作用是可以使用增量编码（delta-encoding）压缩 posting list.posting list 被分成包含 256 个文档 ID 的块，然后使用增量编码和位打包（bit packing）分别压缩每个块：Lucene 计算最大位数需要在块中存储增量，将此信息添加到块头，然后使用此位数对块的所有增量进行编码。这种编码技术在文献中被称为Frame Of Reference (FOR)

posting list 是 [73, 300, 302, 332, 343, 372]，则增量列表将是 [73, 227, 2, 30, 11, 29],分段添加信息到块头，
 step 1：对posting list进行压缩时进行了正序排序。
 step 2：切分成blocks。具体是怎么做的呢？Lucene是规定每个block是256个delta，这里为了简化一下，搞成3个delta。
 step 3：看下每个block最大的delta是多少。上图的第一个block，最大的delta是227，最接近的2次幂是256(8bits)，于是规定这个block里都用8bits来编码（看绿色的header就是8），第二个block，最大的delta是30，最接近的2次幂是32（5bits），于是规定这个block里都用5bit来编码（看绿色的header就是5

## es 如何快速评分和交并集
1. BitMap
例如[1,3,4,7,10]对应的bitmap就是：[1,0,1,1,0,0,1,0,0,1]

2. Roaring bitmaps
 Roaring bitmaps，可以看成bitmap 的优化，原理是高低位bitMap 单独存储；16 个最高位将发布列表分成块。 这意味着，例如，第一个块将编码介于 0 和 65535 之间的值，第二个块将编码介于 65536 和 131071 之间的值，如果块block 大于4096 就使用bitMap ,如果少于的话，就是2bytes 来存储；

3. 合并的时候高效性
- skip list 数据结构
使用 skip list 数据结构。同时遍历 gender 和 age 的 posting list，互相 skip；
使用 bitset 数据结构，对 gender 和 age 两个 filter 分别求出 bitset，对两个 bitset 做 AN 操作
从概念上来说，对于一个很长的 posting list，比如：

[1,3,13,101,105,108,255,256,257]

我们可以把这个 list 分成三个 block：

[1,3,13] [101,105,108] [255,256,257]

然后可以构建出 skip list 的第二层：

[1,101,255]

1,101,255 分别指向自己对应的 block。这样就可以很快地跨 block 的移动指向位置了。

Lucene 自然会对这个 block 再次进行压缩。其压缩方式就是之前介绍的 Frame Of Reference 编码。

- 利用 Bitset 合并
 每个文档按照文档 id 排序对应其中的一个 bit。Bitset 自身就有压缩的特点，其用一个 byte 就可以代表 8 个文档。所以 100 万个文档只需要 12.5 万个 byte。但是考虑到文档可能有数十亿之多，在内存里保存 bitset 仍然是很奢侈的事情。而且对于个每一个 filter 都要消耗一个 bitset，比如 age=18 缓存起来的话是一个 bitset，18<=age<25 是另外一个 filter 缓存起来也要一个 bitset。

如何减少文档数？ 合并前缀，定期把很多行数据合并成一行，这个过程叫compaction；特别对应es嵌套文档来说，可以保存起子文档和父文档的文档 id 是连续的，而且父文档总是最后一个。


