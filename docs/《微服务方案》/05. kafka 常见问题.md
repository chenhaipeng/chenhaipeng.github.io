- https://www.jianshu.com/p/e66438528879
  
# 1.Kafka的Rebalance机制可能造成的影响及解决方案
`Consumer Group -> Group coordinator -> Leader consumer`
- `session.timeout.ms `  10s
- `heartbeat.interval.ms` 3s
- `max.poll.interval.ms` 5分钟

在kafka中，当有新的消费者加入或者订阅topic partition数发生变化是，会触发Rebalance(再均衡，也就是说，分区的所有权从一个消费者转移到另外一个消费者)，Rebalance 顾名思义是重新均衡消费者消费
- 消费成员都向Coordinator发送请求，请求入Consumer Group，Coordinator 从Comsumer选择一个Consumer担任Leader的角色，并把组成员信息以及订阅信息发给Leader
- Leader 会指明哪个comsumer消费那个topic 的partition,一旦分配完成，leader会把这个方案发给Coordinator。Coordinator接收到分配方案之后会把方案发给各个Consumer，大家都知道自己消费那个分区



## 发生的时机
1. 分区数增加的时候
2. 对topic 的订阅发生变化
3. 消费组成员的加入或者离开
4. 消息处理逻辑过重，也即用户线程需要执行很长的时间处理消息，然后再提交offset 失败`heartbeat.interval.ms`参数配置的值周期性向coordinator发送心跳包以证明consumer还活着。
如果消息处理逻辑过重，也即用户线程需要执行很长的时间处理消，但是如果consumer的消息处理逻辑时长超过了`max.poll.interval.ms`，那么此consumer提交offset就会失败：
`heartbeat.interval.ms` 


## rebalance 的影响
1. 可能重复消费
2. 集群不稳定
3. 影响消费速度

## 如何避免
1. **不可避免** 的情况
- 针对分区的增加
- 对topic的订阅增加或者消费者的增加
2. 合理的消费者参数
- `session.timeout.ms` 的session连接超时的时间
- `heartbeat.interval.ms` 心跳时间
- `max.poll.interval.ms` 
3. 保障消费者组处理能力的稳定性

优化建议：优化处理逻辑，快速处理数据；消费和处理进行解耦，使用不同的线程处理；创建消费者时适当减小max.poll.records的配置，默认为500，减少单次消息处理时间。

# 消息中间件怎么保证消息幂等性/一致性？
- 单会话幂等性(幂等型producer)
PID sequence number
缺陷是应用重启，新的producer没有老的producer的状态数据，可能重复

#3. 零拷贝(Zero Copy)技术原理
传统的I/O操作会将同一份数据拷贝2次，并且涉及4次的内核态和用户态的上下文切换，CPU的开销非常大。
零拷贝是依赖操作系统sendfile()支持的，它只需要一次数据拷贝操作，2次内核态和用户态的上下文切换，并且利用DMA直接存储器进行数据的传输，减少了CPU的消耗。
Java的NIO的零拷贝技术是通过FileChannel.transferTo()方法实现的

#16 kafka分区分配策略
kafka内部中存在两种分配策略：Range和RoundRobin。

# Kafka的那些设计让它有如此高的性能？
直接利用Linux操作系统的page cache缓存数据，而不是堆内存
分区
顺序写磁盘
零拷贝技术，提高60%数据发送性能

1. 分布式架构，可以将数据分散到多个节点上进行处理和存储，从而提高了整个系统的吞吐量和可伸缩性。 zookeeper, leader foller,每个消息都可以实现多个副本复制
2. 零拷贝， 以在不拷贝数据的情况下将数据从磁盘读取到内存中
3. 批量处理
4. 压缩技术
5. 消息分区  一个topic 对应多个partition,每个partition 是一个有序的队列
6. 高效的存储结构 
   - segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为- segment索引文件、数据文件.segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充
7. 异步处理

#17 kafka 的目录结构
每个分区对应一个文件夹，文件夹的命名为topic-0，topic-1，内部为.log和.index文件。kafka 采用分片和索引机制，把每个partition 分为多个segment, topic+分区好，

# Kafka 跟RocketMQ吞吐量如何，其他方面呢
- 吞吐量
- 数据可靠性
- 消息投递的实时性
- 消息失败重试
- 分布式事务消息
- 消息回溯
- 消息轨迹
当broker里面topic的partition数量过多，Kafka的性能远远不如rocketmq，因为两者在存储机制上的不同。

kafka和rocketMq都使用文件存储，但是，kafka是一个分区一个文件，当topic过多，分区的总量也会增加，kafka中存在过多的文件，当对消息刷盘时，就会出现文件竞争磁盘，出现性能的下降。
一个partition（分区）一个文件，顺序读写。这样带来的影响是，一个分区只能被一个消费组中的一个 消费线程进行消费，因此可以同时消费的消费端也比较少。
rocketMq中，所有的队列都存储在一个文件中，每个队列的存储的消息量也比较小，因此topic的增加对rocketMq的性能的影响较小。也从而rocketMq可以存在的topic比较多，可以适应比较复杂的业务。
所有的队列存储一个文件（commitlog）中，所以rocketmq是顺序写io，随机读。每次读消息时先读逻辑队列consumQue中的元数据，再从commitlog中找到消息体。增加了开销。



