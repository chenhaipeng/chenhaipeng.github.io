- [ClickHouse介绍](https://zhuanlan.zhihu.com/p/370201180)
- [基于Clickhouse的下一代日志系统技术揭秘](https://mp.weixin.qq.com/s/d2PbeLesLXKLldr4PgMy_g?st=EA0414893622EAD2C42623B2CE68F4207923A2180A21DE2ED4F4F585C38DDE477BD4925453FD349F1D2CA79CB26125654BE953475702D0738F7D4972C97D8F616F26BCF5EC566B7356A98949D68E4E18E6581C08F8759B38E350BE5E8A6745AE8F8875FF6F9C24AFB471A4BF87A51ACB481D43748E401CFBBB026B0A2965436F4882CE57A4D124CAFD27FB2CBCBAD94943803F9DCAA5CCF3C7D29C05F5903E234B3D9B8FCC4A5506E50474718832429F0C0B37199EEEA96557DD524B87F3A0E2653784F50250AD0A39EFC000BA1CD25D5D7B5BC2E9E606B13813E3A0BE8FC90BC2C66D96F6C09B542984E2BCD877A9A0&vid=1688850552871118&cst=BFEC58A4ADA42D7BEB3A23277223585D487954F765832DAD1446E418ECF24CB9A233E154F9FA78BE90AC613674397EAA&deviceid=402f2daf-35b5-43bf-bd2a-fcec64a7e203&version=4.0.9.99149&platform=mac)

- [ClickHouse 核心引擎 MergeTree 解读](https://www.infoq.cn/article/33p0kgzmhj2rffvycr44)

## 重要概念
- [Clickhouse 分布式表&本地表](https://www.cnblogs.com/yisany/p/13524018.html)
- PROJECTION 映射?视图

### 字段类型
- String、LowCardinality(String) , eg:postcode1 LowCardinality(String)
- UInt32 , eg:price UInt32
- Enum8 , type Enum8('terraced' = 1, 'semi-detached' = 2, 'detached' = 3, 'flat' = 4, 'other' = 0),

### 引擎
- ENGINE MergeTree 
- PRIMARY KEY 
- Order by 复合排序键
- index_granularity = 8192, index_granularity_bytes = 0;
    - index_granularity: 显式设置为其默认值8192。这意味着对于每一组8192行，主索引将有一个索引条目，例如，如果表包含16384行，那么索引将有两个索引条目。
    - index_granularity_bytes: 设置为0表示禁止自适应索引粒度。


### 索引类型(一级索引，二级索引)
- 排序键？ 
ORDER BY (ck_timestamp, serviceName, operation, traceID) 
```
│ CREATE TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica
(
    `ck_host` String,
    `ck_offset` UInt64,
    `ck_source` String,
    `ck_timestamp` DateTime,
    `spanID` String CODEC(ZSTD(1)),
    `traceID` String CODEC(ZSTD(1)),
    `ck_map_field` Map(String, String),
    `ck_message` String,
    `source` String CODEC(ZSTD(1)),
    `duration` UInt64 CODEC(ZSTD(1)),
    `startTime` Int64,
    `oTraceID` String CODEC(ZSTD(1)),
    `serviceInstance` String CODEC(ZSTD(1)),
    `serviceName` String CODEC(ZSTD(1)),
    `operation` String CODEC(ZSTD(1)),
    `parentSpanID` String CODEC(ZSTD(1)),
    `ptag` String CODEC(ZSTD(1)),
    `log` String CODEC(ZSTD(2)),
    `statusCode` Int32 CODEC(ZSTD(1)),
    `error` Int8 CODEC(ZSTD(1)),
    `component` LowCardinality(String) CODEC(ZSTD(1)),
    `spanKind` LowCardinality(String) CODEC(ZSTD(1)),
    `access` String CODEC(ZSTD(1)),
    `level` String CODEC(ZSTD(1)),
    `service` String CODEC(ZSTD(1)),
    INDEX idx_trace_id_v2 traceID TYPE bloom_filter(0.001) GRANULARITY 1,
    INDEX idx_tag_key mapKeys(ck_map_field) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_tag_value mapValues(ck_map_field) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_duration duration TYPE minmax GRANULARITY 1
)
ENGINE = MergeTree
PARTITION BY toStartOfDay(ck_timestamp)
ORDER BY (ck_timestamp, serviceName, operation, traceID)
TTL ck_timestamp + toIntervalDay(31)
SETTINGS index_granularity = 8192 │
```


### 函数

## QA
- [Clickhouse MergeTree排序键建立后还能修改吗](https://blog.csdn.net/m0_37795099/article/details/123194574)

```
# 本地表
create table if not exists zhiyanlog_non_shard.hp_ck_test5_replica ON CLUSTER zhiyanlog_sz_non_replica(ck_host String, ck_offset UInt64, ck_source String, ck_timestamp DateTime, ck_map_field  Map(String,String)) engine = MergeTree() PARTITION BY toStartOfDay(ck_timestamp) TTL ck_timestamp + INTERVAL 31 DAY ORDER BY (ck_timestamp) SETTINGS index_granularity = 8192;

# 分布式表
create table if not exists zhiyanlog_non_shard.hp_ck_test5 ON CLUSTER zhiyanlog_sz_non_replica(ck_host String, ck_offset UInt64, ck_source String, ck_timestamp DateTime, ck_map_field  Map(String,String)) engine = Distributed('zhiyanlog_sz_non_replica', 'zhiyanlog_non_shard', 'hp_ck_test5_replica', rand())

```


### crud
```
# create
CREATE TABLE zhiyanlog_non_shard.apm_PTO3zLv95
(
    `ck_host` String,
    `ck_offset` UInt64,
    `ck_source` String,
    `ck_timestamp` DateTime,
    `spanID` String,
    `traceID` String,
    `access` String,
    `ck_map_field` Map(String, String),
    `level` String,
    `service` String,
    `ck_message` String,
    `source` String,
    `duration` Int64,
    `startTime` Int64,
    `oTraceID` String,
    `serviceInstance` String,
    `serviceName` String,
    `operation` String,
    `parentSpanID` String,
    `ptag` String,
    `log` String,
    `statusCode` Int32,
    `error` Int32,
    `component` String,
    `spanKind` String
)
ENGINE = Distributed('zhiyanlog_sz_non_replica', 'zhiyanlog_non_shard', 'apm_PTO3zLv95_replica', rand())


│ CREATE TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica
(
    `ck_host` String,
    `ck_offset` UInt64,
    `ck_source` String,
    `ck_timestamp` DateTime,
    `spanID` String,
    `traceID` String,
    `access` String,
    `ck_map_field` Map(String, String),
    `level` String,
    `service` String,
    `ck_message` String,
    `source` String,
    `duration` Int64,
    `startTime` Int64,
    `oTraceID` String,
    `serviceInstance` String,
    `serviceName` String,
    `operation` String,
    `parentSpanID` String,
    `ptag` String,
    `log` String,
    `statusCode` Int32,
    `error` Int32,
    `component` String,
    `spanKind` String
)
ENGINE = MergeTree
PARTITION BY toStartOfDay(ck_timestamp)
ORDER BY ck_timestamp
TTL ck_timestamp + toIntervalDay(31)
SETTINGS index_granularity = 8192 │


CREATE TABLE IF NOT EXISTS spans_local_replica ON CLUSTER zhiyanlog_sz_non_replica (
     timestamp DateTime64(9) CODEC(Delta, ZSTD(1)),
     traceID String CODEC(ZSTD(1)),
     oTraceID String CODEC(ZSTD(1)),
     spanID String CODEC(ZSTD(1)),
     parentSpanID String CODEC(ZSTD(1)),
     startTime DateTime64(9) CODEC(Delta, ZSTD(1)),
     serviceName LowCardinality(String) CODEC(ZSTD(1)),
	 serviceinstance LowCardinality(String) CODEC(ZSTD(1)),
     operation LowCardinality(String) CODEC(ZSTD(1)),
     spanKind LowCardinality(String) CODEC(ZSTD(1)),
     error bool CODEC(ZSTD(1)),   //是否异常
     statusCode Int32 CODEC(ZSTD(1)),
     duration UInt64 CODEC(ZSTD(1)),
     component LowCardinality(String) CODEC(ZSTD(1)),
     tags Map(String, String) CODEC(ZSTD(1)),
     ptag String CODEC(ZSTD(1)),
     log String CODEC(ZSTD(2)),
     INDEX idx_trace_id_v2 traceID TYPE bloom_filter(0.001) GRANULARITY 1,  
     INDEX idx_tag_key mapKeys(tags) TYPE bloom_filter(0.01) GRANULARITY 1,  
     INDEX idx_tag_value mapValues(tags) TYPE bloom_filter(0.01) GRANULARITY 1,
     INDEX idx_ptag_key mapKeys(ptags) TYPE bloom_filter(0.01) GRANULARITY 1,
     INDEX idx_ptag_value mapValues(ptags) TYPE bloom_filter(0.01) GRANULARITY 1,
     INDEX idx_duration duration TYPE minmax GRANULARITY 1
) ENGINE MergeTree()
TTL toDateTime(timestamp) + toIntervalDay(1) 
PARTITION BY toDate(timestamp) 
ORDER BY (serviceName, spanName, toUnixTimestamp(timestamp), traceID)   
SETTINGS index_granularity=8192, ttl_only_drop_parts = 1, merge_with_ttl_timeout=3600;


#update

ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica ON CLUSTER zhiyanlog_sz_non_replica MODIFY COLUMN traceID String CODEC(ZSTD(1));

ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95 ON CLUSTER zhiyanlog_sz_non_replica MODIFY COLUMN traceID String CODEC(ZSTD(1));

# 多个字段
ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica ON CLUSTER zhiyanlog_sz_non_replica MODIFY COLUMN spanID String CODEC(ZSTD(1)), MODIFY COLUMN access String CODEC(ZSTD(1)),  MODIFY COLUMN  level String CODEC(ZSTD(1)), MODIFY COLUMN service String CODEC(ZSTD(1)), MODIFY COLUMN source String CODEC(ZSTD(1)),MODIFY COLUMN oTraceID String CODEC(ZSTD(1)),MODIFY COLUMN serviceName String CODEC(ZSTD(1)) ,MODIFY COLUMN serviceInstance String CODEC(ZSTD(1)),MODIFY COLUMN operation String CODEC(ZSTD(1)),MODIFY COLUMN  parentSpanID String CODEC(ZSTD(1)),MODIFY COLUMN ptag String CODEC(ZSTD(1)), MODIFY COLUMN log String CODEC(ZSTD(2)),MODIFY COLUMN statusCode Int32 CODEC(ZSTD(1)),MODIFY COLUMN duration UInt64 CODEC(ZSTD(1)),MODIFY COLUMN error bool CODEC(ZSTD(1)),MODIFY COLUMN component LowCardinality(String) CODEC(ZSTD(1)),MODIFY COLUMN spanKind LowCardinality(String) CODEC(ZSTD(1)), MODIFY COLUMN error bool CODEC(ZSTD(1));

ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95 ON CLUSTER zhiyanlog_sz_non_replica MODIFY COLUMN spanID String CODEC(ZSTD(1)), MODIFY COLUMN access String CODEC(ZSTD(1)),  MODIFY COLUMN  level String CODEC(ZSTD(1)), MODIFY COLUMN service String CODEC(ZSTD(1)), MODIFY COLUMN source String CODEC(ZSTD(1)),MODIFY COLUMN oTraceID String CODEC(ZSTD(1)),MODIFY COLUMN serviceName String CODEC(ZSTD(1)) ,MODIFY COLUMN serviceInstance String CODEC(ZSTD(1)),MODIFY COLUMN operation String CODEC(ZSTD(1)),MODIFY COLUMN  parentSpanID String CODEC(ZSTD(1)),MODIFY COLUMN ptag String CODEC(ZSTD(1)), MODIFY COLUMN log String CODEC(ZSTD(2)),MODIFY COLUMN statusCode Int32 CODEC(ZSTD(1)),MODIFY COLUMN duration UInt64 CODEC(ZSTD(1)),MODIFY COLUMN error bool CODEC(ZSTD(1)),MODIFY COLUMN component LowCardinality(String) CODEC(ZSTD(1)),MODIFY COLUMN spanKind LowCardinality(String) CODEC(ZSTD(1)), MODIFY COLUMN error bool CODEC(ZSTD(1));

# drop
ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica ON CLUSTER zhiyanlog_sz_non_replica MODIFY COLUMN error bool CODEC(ZSTD(1));


ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica ON CLUSTER zhiyanlog_sz_non_replica DROP COLUMN IF EXISTS access,DROP COLUMN IF EXISTS service ,DROP COLUMN IF EXISTS level ;

ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95 ON CLUSTER zhiyanlog_sz_non_replica DROP COLUMN IF EXISTS access,DROP COLUMN IF EXISTS service ,DROP COLUMN IF EXISTS level ;

# add index
ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica ON CLUSTER zhiyanlog_sz_non_replica  ADD   INDEX idx_trace_id_v2 traceID TYPE bloom_filter(0.001) GRANULARITY 1, ADD INDEX idx_tag_key mapKeys(ck_map_field) TYPE bloom_filter(0.01) GRANULARITY 1, ADD  INDEX idx_tag_value mapValues(ck_map_field) TYPE bloom_filter(0.01) GRANULARITY 1, ADD INDEX idx_duration duration TYPE minmax GRANULARITY 1;


ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95 ON CLUSTER zhiyanlog_sz_non_replica  ADD   INDEX idx_trace_id_v2 traceID TYPE bloom_filter(0.001) GRANULARITY 1, ADD INDEX idx_tag_key mapKeys(ck_map_field) TYPE bloom_filter(0.01) GRANULARITY 1, ADD  INDEX idx_tag_value mapValues(ck_map_field) TYPE bloom_filter(0.01) GRANULARITY 1, ADD INDEX idx_duration duration TYPE minmax GRANULARITY 1;

#
ALTER TABLE zhiyanlog_non_shard.apm_PTO3zLv95_replica modify ORDER BY (ck_timestamp,serviceName,operation,traceID);


# 查询
SELECT partition AS `分区`, sum(rows) AS `总行数`, formatReadableSize(sum(data_uncompressed_bytes)) AS `原始大小`, formatReadableSize(sum(data_compressed_bytes)) AS `压缩大小`, round((sum(data_compressed_bytes) / sum(data_uncompressed_bytes)) * 100, 0) AS `压缩率` FROM system.parts WHERE (database IN ('zhiyanlog_non_shard')) AND (table IN ('apm_PTO3zLv95_replica')) AND (partition LIKE '2022-10-%') GROUP BY partition ORDER BY partition ASC


SELECT * FROM zhiyanlog_non_shard.apm_PTO3zLv95 WHERE ck_timestamp >= toDateTime('2022-10-24 00:00:00') AND ck_timestamp < toDateTime('2022-10-24 12:00:00') AND ck_map_field['ip'] = toString('9.219.157.91') AND `serviceName` = toString('prd-product-micro-service-scm-service-batch') ORDER BY ck_timestamp desc, ck_offset desc LIMIT 50 OFFSET 0 FORMAT JSON;


# 解析
explain indexes = 1 SELECT * FROM zhiyanlog_non_shard.apm_PTO3zLv95_replica WHERE ck_timestamp >= toDateTime('2022-10-24 00:00:00') AND ck_timestamp < toDateTime('2022-10-24 23:59:59')  AND  ck_map_field['x-request-id'] = '5437390ff3cf748957d74aa296f4ad96' ORDER BY ck_timestamp desc, ck_offset desc LIMIT 50 OFFSET 0

# rename

RENAME TABLE zhiyan_log.apm_6xYKFXYxo_trace_replica TO zhiyan_log.apm_6xYKFXYxo_trace_replica5 ON CLUSTER clickhouse_teg_it5_test_1_replica
RENAME TABLE  zhiyan_log.apm_6xYKFXYxo_trace to zhiyan_log.apm_6xYKFXYxo_trace5 on cluster 'clickhouse_teg_it5_test_1_replica'


RENAME TABLE  tps_qq.tjg_test to tps_qq.tjg_test_bak on cluster 'zhiyanlog_sz'

RENAME TABLE  tps_qq.tjg_test_replica to tps_qq.tjg_test_replica_bak on cluster 'zhiyanlog_sz'

CREATE OR REPLACE VIEW tps_qq.tjg_test AS SELECT timestamp ck_timestamp,0 ck_offset,* from tps_qq.spans_v2




```

### 数据迁移
- [Clickhouse 数据迁移](https://cloud.tencent.com/developer/article/1779986)
- [从自建ClickHouse迁移上云](https://help.aliyun.com/document_detail/208529.html)

```
# 迁移
clickhouse-client --host="<old host>" --port="<oldport>" --user="<old user name>" --password="<old password>"  --query="select * from <database_name>.<table_name> FORMAT CSV"  > table.csv

RENAME TABLE tps.qq.apm_6xYKFXYxo_trace_replica TO zhiyan_log.apm_6xYKFXYxo_trace_replica5 ON CLUSTER clickhouse_teg_it5_test_1_replica



```

http://v3.open.oa.com/developer-center/apps
### 视图
- [「ClickHouse系列」ClickHouse中的物化视图详解](https://cloud.tencent.com/developer/article/1988528)

## 查询排查
### 执行计划
### 查询进程与kill
```

SELECT query_start_time, query_duration_ms, query, initial_query_id FROM system.query_log WHERE (event_time >= (now() - toIntervalMinute(1))) AND (query_kind = 'Select') AND (type = 'QueryFinish') AND (query LIKE '%entrance.whitelist%') ORDER BY query_start_time DESC LIMIT 1113\G


SELECT * FROM system.query_log WHERE (event_time >= (now() - toIntervalMinute(1))) AND (query_kind = 'Select') AND (type = 'QueryFinish') AND (query LIKE '%entrance.whitelist%') ORDER BY query_start_time DESC LIMIT 1113\G


SELECT query_start_time, query_duration_ms, query, initial_query_id FROM system.query_log WHERE (event_time >= (now() - toIntervalMinute(1))) AND (query_kind = 'Select') AND (type = 'QueryFinish') AND (query LIKE '%entrance.whitelist%') ORDER BY query_start_time DESC LIMIT 1113\G


SELECT query_start_time, query_duration_ms, query, initial_query_id FROM cluster('default_cluster', 'system', 'query_log') ARRAY JOIN tables WHERE tables != 'system' and  (event_time >= (now() - toIntervalMinute(5))) AND (query_kind = 'Select') AND (type = 'QueryFinish') AND (query LIKE '%32a9e6a02e92068b34a8fbd35aacd464%') ORDER BY query_start_time DESC LIMIT 1113


SELECT query_start_time, query_duration_ms, query,tables,initial_query_id FROM cluster('default_cluster', 'system', 'query_log') ARRAY JOIN tables WHERE tables != 'system.query_log' and  (event_time >= (now() - toIntervalMinute(5))) AND (query_kind = 'Select') AND (type = 'QueryFinish') AND (query LIKE '%spans_trace_id_ts%') ORDER BY query_start_time DESC LIMIT 1113\G

SELECT spans_local_v1.timestamp, spans_local_v1.spanName, spans_local_v1.serviceName, spans_local_v1.ptags, spans_local_v1.duration FROM tps_qq.spans_local_v1 WHERE (((((((has(mapValues(ptags), 'release') AND has(mapKeys(ptags), 'build_type')) AND ((ptags['build_type']) = 'release')) AND (duration > 10000000)) AND (spanName = 'QQ_RegPrxySvc')) AND (serviceName = 'android')) AND (serviceName = 'android')) AND (timestamp <= '2022-12-22 20:20:00')) AND (timestamp >= '2022-12-22 20:10:00')

```


### 元数据相关
https://clickhouse.com/docs/zh/guides/improving-query-performance/sparse-primary-indexes/
```
SELECT
    part_type,
    path,
    formatReadableQuantity(rows) AS rows,
    formatReadableSize(data_uncompressed_bytes) AS data_uncompressed_bytes,
    formatReadableSize(data_compressed_bytes) AS data_compressed_bytes,
    formatReadableSize(primary_key_bytes_in_memory) AS primary_key_bytes_in_memory,
    marks,
    formatReadableSize(bytes_on_disk) AS bytes_on_disk
FROM system.parts
WHERE (table = 'hits_UserID_URL') AND (active = 1)
FORMAT Vertical;
```



