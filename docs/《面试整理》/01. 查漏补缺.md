
# 20230912 查漏补缺
1. 整理各个存储的共性（es、clickhouse、kafka）具体的存储文件格式与底层结构
2. 分布式锁的实现（redission）
3. 各个jdk  gc实现与区别是什么
4. elasticsearch 底层存储结构是什么


## kafka 
- segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为- segment索引文件、数据文件.segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充

## clickhouse
> https://saintbacchus.github.io/2021/08/15/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAClickhouse-%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/
clickhouse 每次写入数据的时候，都新建一个目录，`datapart`
- min_block 和max_black 1_1_1_0
- 


partition是分区的值, 根据建表的分区表示计算得来, 是一个规定的值; Clickhouse的目录并非按照分区规整的, 在数据目录下, 只有DataPart这层数据了, 也就是说, 通一个分区可能在多个DataPart上, 如上面的1_1_1_0和1_2_2_0
min_block和max_block中的block是一个单挑递增的计数器, 插入3次后, 计数器就变成了3. 新的DataPart的min_block和max_block是一样的, 但在后续merge之后, 会变成一个范围值.
level表示DataPart生命年龄, 当出现merge或者mutation操作时, level就会加1

- primary.idx主键索引, 或者成为一级索引，稀疏索引 以8192划分为一组grand 颗粒
- skp_idx_a.idx2和skp_idx_a.mrk3 跳数索引, 或者叫做二级索引.
- num.mrk  mrk标记
- data.bin 数据块

## redis 锁
set命令要用set key value px milliseconds nx；
value要具有唯一性；
释放锁时要验证value值，不能误解锁；
事实上这类琐最大的缺点就是它加锁时只作用在一个Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况：

1. 有什么问题？
在Redis的master节点上拿到了锁；
但是这个加锁的key还没有同步到slave节点；
master故障，发生故障转移，slave节点升级为master节点；
导致锁丢失。

2. 如何解决
为了取到锁，客户端应该执行以下操作: 其实`定义获取锁超时的的机制`，请求失效重新获取，锁 > N/2+1 - unixTime 少于锁失效， 持有锁时间
= 真正有效时间- 获取锁的时间

- 获取当前Unix时间，以毫秒为单位。
- （请求网络IO时间> 锁失效时间，重新请求） 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。（
- （客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间 >N/2+1，这里是3个节点 并且时间少于失效时间才算成功）
客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。
- 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。
如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在`所有的Redis实例上`进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。  

## 垃圾回收之CMS、G1、ZGC对比
> https://juejin.cn/post/7216967809158299703

### ZGC(The Z Garbage Collector) 目标是适用于大内存的内存管理和回收，基于Region内存布局
- 停顿的时间不超过10ms;
- 停顿的时间不随着堆的大小或者活跃的对象而增加
- 支持最高16TB 的内存  

#### 原理步骤
ZGC只有三个STW阶段：初始标记，再标记，初始转移。


1. 标记清除Mark-sweep
2. 复制copying
3. 标记整理算法 Mark-Compact
4. 分代回收 generation collection

### CMS收集器（Concurrent Mark Sweep）收集器是一种以获取停顿时间为目标的收集器，是因为CMS收集器工作是，GC工作线程与用户线程可以并发执行
- 初设标记（CMS initial mark）
- 并发标记（CMS concurrent mark）
- 重新标记 （CMS remark）
- 并发清除 （CMS concurrent sweep）

优点: 并发收集、低停顿。
缺点: 对cpu 资源比较敏感，容易产生碎片

### G1
G1 算法取消了堆中年轻代与老年代的物理划分，但它仍然属于分代收集器。G1 算法将堆划分为若干个区域，称作 Region
- ZGC，ZGC可以看做是G1之上更细粒度的内存管理策略。由于内存的不断分配回收会产生大量的内存碎片空间
- G1 的年轻代回收，采用复制算法，并行进行收集，收集过程会 STW。
- G1 的老年代回收时也同时会对年轻代进行回收。主要分为四个阶段：
依然是初始标记阶段完成对根对象的标记，这个过程是STW的；
并发标记阶段，这个阶段是和用户线程并行执行的；
最终标记阶段，完成三色标记周期；
复制/清除阶段，这个阶段会优先对可回收空间较大的 Region 进行回收，即 garbage first，这也是 G1 名称的由来。

### elasticsearch 